{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading SummEval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "script_dir = \"../src\"\n",
    "\n",
    "sys.path.append(script_dir)\n",
    "\n",
    "from gpt_model import Model\n",
    "\n",
    "random.seed(42)\n",
    "with open(\"../data/summeval.json\") as file:\n",
    "    data = json.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4\n"
     ]
    }
   ],
   "source": [
    "with open(\"../api_keys.json\", \"r\") as file:\n",
    "    api_keys = json.load(file)\n",
    "OPENAI_API_KEY = api_keys[\"openai\"]\n",
    "\n",
    "gpt4 = Model(model=\"gpt-4\", temperature=0.0, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSION = \"coherence\"\n",
    "DIMENSION_RUBRIC = {\n",
    "    \"coherence\":'Coherence ( 1 - 5 ) - the collective quality of all sentences. We align this dimension with the DUC quality question of structure and coherence whereby \"the summary should be well-structured and well-organized. The summary should not just be a heap of related information, but should build from sentence to a coherent body of information about a topic.\"',\n",
    "    \"consistency\":\"Consistency ( 1 - 5 ) - the factual alignment between the summary and the summarized source. A factually consistent summary contains only statements that are entailed by the source document. Annotators were also asked to penalize summaries that contained hallucinated facts.\",\n",
    "    \"fluency\":'Fluency ( 1 - 5 ) - the quality of individual sentences. Drawing again from the DUC quality guidelines, sentences in the summary \"should have no formatting problems, capitalization errors or obviously ungrammatical sentences (e.g., fragments, missing components) that make the text difficult to read.\"',\n",
    "    \"relevance\":\"Relevance ( 1 - 5 ) - selection of important content from the source. The summary should include only important information from the source document. Annotators were instructed to penalize summaries which contained redundancies and excess information.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = pd.read_pickle(f\"../data/{DIMENSION}/sample.pkl\")\n",
    "\n",
    "sampled_source = list()\n",
    "sampled_summary = list()\n",
    "sampled_score = list()\n",
    "\n",
    "for sample in sample_list:\n",
    "    sampled_source.append(sample[\"source\"])\n",
    "    sampled_summary.append(sample[\"system_output\"])\n",
    "    sampled_score.append(sample[\"scores\"][DIMENSION])\n",
    "\n",
    "\n",
    "with open(\"../prompts/think_aloud/gpt/system_prompt.txt\", \"r\") as file:\n",
    "    sys_prompt = file.read()\n",
    "with open(\"../prompts/think_aloud/gpt/user_prompt.txt\", \"r\") as file:\n",
    "    user_prompt = file.read()\n",
    "\n",
    "prompt_list = [\n",
    "    {\"role\":\"system\", \"content\": sys_prompt.format(DIMENSION, DIMENSION, DIMENSION, DIMENSION)},\n",
    "    {\"role\": \"user\", \"content\": user_prompt.format(DIMENSION, DIMENSION_RUBRIC[DIMENSION], sampled_source[0], sampled_summary[0], sampled_score[0], \n",
    "                                                   sampled_source[1], sampled_summary[1], sampled_score[1], sampled_source[2], sampled_summary[2], sampled_score[2],\n",
    "                                                   sampled_source[3], sampled_summary[3], sampled_score[3])}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Think Aloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_response = gpt4.ask_chatgpt(prompt_list)\n",
    "gpt4_response = ''.join(re.findall(r'\\{[^}]*\\}', gpt4_response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Check if the summary is well-structured and well-organized, not just a heap of related information.',\n",
       " 2: 'Ensure the summary builds from sentence to a coherent body of information about a topic.',\n",
       " 3: 'Assess if the summary maintains a logical flow of ideas and events.',\n",
       " 4: 'Evaluate if the summary provides a clear and concise overview of the main points in the news article.',\n",
       " 5: 'Consider if the summary maintains the context and meaning of the original news article.',\n",
       " 6: 'Check if the summary avoids unnecessary repetition of information.',\n",
       " 7: 'Ensure the summary does not introduce new information not present in the original article.',\n",
       " 8: 'Assess if the summary maintains the same tone and style as the original news article.',\n",
       " 9: 'Consider if the summary is free from grammatical and spelling errors, which can disrupt coherence.',\n",
       " 10: 'Evaluate if the summary maintains the same perspective as the original news article.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(gpt4_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
